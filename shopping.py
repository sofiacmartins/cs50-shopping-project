import csv
import sys

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

"""
ğŸ›’ Shopping - Sistema de PrevisÃ£o de Compras Online com IA

Este programa utiliza machine learning (algoritmo K-Nearest Neighbors)
para prever se um cliente numa loja online irÃ¡ completar uma compra,
baseado em 17 caracterÃ­sticas do seu comportamento de navegaÃ§Ã£o.

Features Implementadas:
    1. load_data() - Carregamento e processamento de dados CSV
    2. train_model() - Treino com K-Nearest Neighbors (k=1)
    3. evaluate() - AvaliaÃ§Ã£o com Sensitivity e Specificity
    4. validate_data() - ValidaÃ§Ã£o automÃ¡tica de integridade [IA]
    5. analyze_dataset() - AnÃ¡lise estatÃ­stica do dataset [IA]

Dataset: 12.330 sessÃµes reais de utilizadores de e-commerce
Resultados: Accuracy ~83% | Sensitivity ~41% | Specificity ~91%

Desenvolvido por: Sofia Martins
Data: Novembro 2025
"""

TEST_SIZE = 0.4  # 40% dos dados para teste, 60% para treino


def main():
    """
    FunÃ§Ã£o principal que coordena todo o fluxo do programa.
    """
    # Verificar argumentos da linha de comandos
    if len(sys.argv) != 2:
        sys.exit("Usage: python shopping.py data")

    # PASSO 1: Carregar dados do CSV
    # Transforma texto em dados numÃ©ricos prontos para ML
    evidence, labels = load_data(sys.argv[1])
    
    # PASSO 2: Validar dados (FEATURE EXTRA 1 - desenvolvida com IA)
    # Garante que os dados estÃ£o corretos antes do treino
    is_valid, errors = validate_data(evidence, labels)
    if not is_valid:
        print("Erros encontrados:")
        for error in errors[:10]:  # Mostrar apenas primeiros 10
            print(f"  - {error}")
        sys.exit(1)
    
    # PASSO 3: Analisar estatÃ­sticas (FEATURE EXTRA 2 - desenvolvida com IA)
    # Mostra distribuiÃ§Ã£o dos dados e explica os resultados
    analyze_dataset(evidence, labels)
    
    # PASSO 4: Dividir dados em treino (60%) e teste (40%)
    X_train, X_test, y_train, y_test = train_test_split(
        evidence, labels, test_size=TEST_SIZE
    )

    # PASSO 5: Treinar o modelo KNN
    model = train_model(X_train, y_train)
    
    # PASSO 6: Fazer previsÃµes nos dados de teste
    predictions = model.predict(X_test)
    
    # PASSO 7: Avaliar a qualidade das previsÃµes
    sensitivity, specificity = evaluate(y_test, predictions)

    # PASSO 8: Mostrar resultados finais
    print(f"Correct: {(y_test == predictions).sum()}")
    print(f"Incorrect: {(y_test != predictions).sum()}")
    print(f"True Positive Rate: {100 * sensitivity:.2f}%")
    print(f"True Negative Rate: {100 * specificity:.2f}%")


def load_data(filename):
    """
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FUNÃ‡ÃƒO 1 (OBRIGATÃ“RIA): CARREGAR E PROCESSAR DADOS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Transforma um CSV de texto em dados numÃ©ricos para ML.
    
    INPUT: Nome do ficheiro CSV
    OUTPUT: Tuplo (evidence, labels)
            - evidence: lista de 12.330 listas com 17 features cada
            - labels: lista de 12.330 valores (0 ou 1)
    
    APRESENTAÃ‡ÃƒO: Explicar o mapeamento de meses e as conversÃµes
    """
    
    # Inicializar listas vazias
    evidence = []   # Vai guardar as 17 caracterÃ­sticas de cada sessÃ£o
    labels = []     # Vai guardar se comprou (1) ou nÃ£o (0)
    
    # IMPORTANTE PARA APRESENTAÃ‡ÃƒO: DicionÃ¡rio para converter meses
    # No CSV estÃ¡ "Jan", "Feb" etc. â†’ Precisamos de nÃºmeros (0-11)
    months = {
        "Jan": 0, "Feb": 1, "Mar": 2, "Apr": 3, "May": 4, "June": 5,
        "Jul": 6, "Aug": 7, "Sep": 8, "Oct": 9, "Nov": 10, "Dec": 11
    }
    
    # Abrir ficheiro CSV
    with open(filename, 'r') as file:
        # IMPORTANTE: DictReader lÃª cada linha como dicionÃ¡rio
        # Permite aceder aos valores pelo nome: row["Month"]
        reader = csv.DictReader(file)

        # Processar cada sessÃ£o de utilizador (12.330 no total)
        for row in reader:
            # Criar lista com 17 FEATURES NUMÃ‰RICAS para este utilizador
            # APRESENTAÃ‡ÃƒO: Destacar as conversÃµes int() e float()
            user_evidence = [
                # Features 0-5: PÃ¡ginas visitadas e duraÃ§Ãµes
                int(row["Administrative"]),              # NÂº pÃ¡ginas admin
                float(row["Administrative_Duration"]),   # Tempo em admin
                int(row["Informational"]),               # NÂº pÃ¡ginas info
                float(row["Informational_Duration"]),    # Tempo em info
                int(row["ProductRelated"]),              # NÂº pÃ¡ginas produtos
                float(row["ProductRelated_Duration"]),   # Tempo em produtos
                
                # Features 6-9: MÃ©tricas do Google Analytics
                float(row["BounceRates"]),               # Taxa de rejeiÃ§Ã£o
                float(row["ExitRates"]),                 # Taxa de saÃ­da
                float(row["PageValues"]),                # Valor da pÃ¡gina
                float(row["SpecialDay"]),                # Proximidade a data especial
                
                # Feature 10: AQUI USA O DICIONÃRIO! "Feb" â†’ 1
                months[row["Month"]],
                
                # Features 11-14: InformaÃ§Ã£o tÃ©cnica do utilizador
                int(row["OperatingSystems"]),            # Sistema operativo
                int(row["Browser"]),                     # Navegador
                int(row["Region"]),                      # RegiÃ£o geogrÃ¡fica
                int(row["TrafficType"]),                 # Tipo de trÃ¡fego
                
                # Feature 15: EXPRESSÃƒO CONDICIONAL TERNÃRIA
                # Se "Returning_Visitor" â†’ 1, senÃ£o â†’ 0
                1 if row["VisitorType"] == "Returning_Visitor" else 0,
                
                # Feature 16: Outra expressÃ£o condicional
                # Se "TRUE" â†’ 1, senÃ£o â†’ 0
                1 if row["Weekend"] == "TRUE" else 0
            ]
            
            # Adicionar esta sessÃ£o Ã  lista geral
            evidence.append(user_evidence)
            
            # Adicionar o LABEL: comprou (1) ou nÃ£o (0)
            # Esta Ã© a variÃ¡vel que queremos PREVER!
            labels.append(1 if row["Revenue"] == "TRUE" else 0)
    
    # Retornar dados processados
    # No final: 12.330 listas de 17 nÃºmeros + 12.330 labels
    return (evidence, labels)


def train_model(evidence, labels):
    """
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FUNÃ‡ÃƒO 2 (OBRIGATÃ“RIA): TREINAR MODELO KNN
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Treina um classificador K-Nearest Neighbors com k=1.
    
    INPUT: evidence (lista de features), labels (lista de resultados)
    OUTPUT: Modelo treinado pronto para fazer previsÃµes
    
    APRESENTAÃ‡ÃƒO: Explicar o que Ã© KNN com analogia:
    "Procura o vizinho mais parecido no histÃ³rico e prevÃª o mesmo"
    """
    
    # Criar classificador KNN com k=1 (apenas 1 vizinho mais prÃ³ximo)
    # APRESENTAÃ‡ÃƒO: k=1 significa "olha sÃ³ para a pessoa MAIS parecida"
    model = KNeighborsClassifier(n_neighbors=1)
    
    # TREINAR o modelo - aqui acontece a "aprendizagem"!
    # O modelo MEMORIZA os 12.330 exemplos e seus resultados
    # ANALOGIA: Como mostrar 12.330 exemplos a um estudante
    model.fit(evidence, labels)
    
    # Retornar modelo treinado
    return model


def evaluate(labels, predictions):
    """
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FUNÃ‡ÃƒO 3 (OBRIGATÃ“RIA): AVALIAR QUALIDADE DO MODELO
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Calcula Sensitivity e Specificity do modelo.
    
    INPUT: labels reais, predictions do modelo
    OUTPUT: (sensitivity, specificity)
    
    APRESENTAÃ‡ÃƒO: Explicar com exemplos:
    - Sensitivity: "Dos que compraram, quantos % acertei?"
    - Specificity: "Dos que NÃƒO compraram, quantos % acertei?"
    """
    
    # Inicializar contadores
    # APRESENTAÃ‡ÃƒO: Explicar TP, TN com exemplos concretos
    true_positives = 0   # Previu compra E comprou â†’ ACERTOU!
    true_negatives = 0   # Previu nÃ£o-compra E nÃ£o comprou â†’ ACERTOU!
    total_positives = 0  # Total de compradores reais
    total_negatives = 0  # Total de nÃ£o-compradores reais
    
    # Percorrer todas as previsÃµes
    # zip() permite iterar sobre duas listas simultaneamente
    for actual, predicted in zip(labels, predictions):
        # Se a pessoa REALMENTE COMPROU (actual = 1)
        if actual == 1:
            total_positives += 1
            # E o modelo TAMBÃ‰M PREVIU compra (predicted = 1)
            if predicted == 1:
                true_positives += 1  # ACERTOU!
        # Se a pessoa NÃƒO COMPROU (actual = 0)
        else:
            total_negatives += 1
            # E o modelo TAMBÃ‰M PREVIU nÃ£o-compra (predicted = 0)
            if predicted == 0:
                true_negatives += 1  # ACERTOU!
    
    # Calcular SENSITIVITY (True Positive Rate)
    # FÃ³rmula: TP / Total Positivos
    # APRESENTAÃ‡ÃƒO: "Dos 100 compradores, identifiquei 41" â†’ 41%
    sensitivity = true_positives / total_positives if total_positives > 0 else 0
    
    # Calcular SPECIFICITY (True Negative Rate)
    # FÃ³rmula: TN / Total Negativos
    # APRESENTAÃ‡ÃƒO: "Dos 1000 nÃ£o-compradores, identifiquei 910" â†’ 91%
    specificity = true_negatives / total_negatives if total_negatives > 0 else 0
    
    # Retornar as duas mÃ©tricas
    return (sensitivity, specificity)


def validate_data(evidence, labels):
    """
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FEATURE EXTRA 1 (COMPLEXA): VALIDAÃ‡ÃƒO DE DADOS
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    PROMPT USADO:   "Cria funÃ§Ã£o para validar dados de ML. Verifica:
                    17 features por entrada, labels 0 ou 1, sem None."
    
    VALOR: Previne crashes durante o treino ao validar dados primeiro.
    
    APRESENTAÃ‡ÃƒO: Mostrar que Ã© executada ANTES do treino e o output
    "âœ“ ValidaÃ§Ã£o: 12330 entradas vÃ¡lidas..."
    """
    
    errors = []  # Lista para acumular erros encontrados
    
    # VALIDAÃ‡ÃƒO 1: Verificar se hÃ¡ dados
    if len(evidence) == 0:
        errors.append("Nenhum dado foi carregado")
        return (False, errors)
    
    # VALIDAÃ‡ÃƒO 2: Verificar nÃºmero de features (deve ser 17)
    expected_features = 17
    for i, entry in enumerate(evidence):
        if len(entry) != expected_features:
            errors.append(f"Entrada {i}: esperadas {expected_features} features, encontradas {len(entry)}")
            if len(errors) >= 5:  # Limitar mensagens
                break
    
    # VALIDAÃ‡ÃƒO 3: Verificar labels vÃ¡lidos (apenas 0 ou 1)
    valid_labels = {0, 1}
    for i, label in enumerate(labels):
        if label not in valid_labels:
            errors.append(f"Label {i}: valor invÃ¡lido {label} (deve ser 0 ou 1)")
            if len(errors) >= 10:
                break
    
    # VALIDAÃ‡ÃƒO 4: Verificar valores None
    for i, entry in enumerate(evidence[:100]):  # Verificar primeiras 100
        if None in entry:
            errors.append(f"Entrada {i}: contÃ©m valores None")
    
    # Determinar se Ã© vÃ¡lido
    is_valid = len(errors) == 0
    
    # Mostrar mensagem apropriada
    if is_valid:
        print(f"âœ“ ValidaÃ§Ã£o: {len(evidence)} entradas vÃ¡lidas com {expected_features} features cada")
    else:
        print(f"âœ— ValidaÃ§Ã£o: encontrados {len(errors)} erros")
    
    return (is_valid, errors)


def analyze_dataset(evidence, labels):
    """
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    FEATURE EXTRA 2 (REGULAR): ANÃLISE ESTATÃSTICA
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    PROMPT USADO:   "Cria funÃ§Ã£o de anÃ¡lise estatÃ­stica. Conta
                    positivos/negativos, calcula percentagens,
                    alerta se desbalanceado (< 30%)."
    
    VALOR:  Explica PORQUÃŠ sensitivity Ã© 41% e specificity 91%.
            Dataset desbalanceado: 85% nÃ£o compram!
    
    APRESENTAÃ‡ÃƒO: Mostrar o quadro formatado que aparece no output.
    """
    
    # Contar compradores e nÃ£o-compradores
    total = len(labels)
    positives = sum(labels)       # Quantos compraram (label=1)
    negatives = total - positives # Quantos nÃ£o compraram (label=0)
    
    # Mostrar estatÃ­sticas formatadas
    print("\n" + "="*50)
    print("ğŸ“Š ANÃLISE DO DATASET")
    print("="*50)
    print(f"Total de sessÃµes: {total}")
    print(f"Compradores: {positives} ({100*positives/total:.1f}%)")
    print(f"NÃ£o-compradores: {negatives} ({100*negatives/total:.1f}%)")
    print(f"RÃ¡cio: 1:{negatives/positives:.1f}")
    
    # Verificar balance do dataset
    # APRESENTAÃ‡ÃƒO: Isto explica porque specificity Ã© alta (91%)!
    # O modelo vÃª 5.5x mais nÃ£o-compradores, aprende melhor a identificÃ¡-los
    if positives / total < 0.3:
        print("âš ï¸  Dataset desbalanceado (poucos compradores)")
    else:
        print("âœ“ Dataset razoavelmente balanceado")
    
    print("="*50 + "\n")


# Ponto de entrada do programa
if __name__ == "__main__":
    main()